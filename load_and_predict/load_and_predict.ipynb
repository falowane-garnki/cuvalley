{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d9ee1ba-30cf-4ea2-835e-ff64950fb31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import os\n",
    "import gzip\n",
    "import shutil\n",
    "import pandas as pd\n",
    "\n",
    "from data_processing import *\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ebde7420-2065-4b00-b1f3-f131db07f380",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpack(dir_path = 'data/'):\n",
    "    list_of_files = glob(dir_path + '*.gz')\n",
    "    for f in glob(dir_path + '*.gz'):\n",
    "        with gzip.open(f, 'rb') as f_in:\n",
    "            with open(f[:-3] + '.csv', 'wb') as f_out:\n",
    "                shutil.copyfileobj(f_in, f_out)\n",
    "            \n",
    "unpack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9923843c-2fcc-4595-8572-ce504d959756",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge(dir_path = 'data/'):\n",
    "    files = sorted([f for f in os.listdir(dir_path) if f[-6:] == '00.csv'])\n",
    "    merged_df = pd.concat([pd.read_csv(dir_path + f) for f in files])\n",
    "\n",
    "    merged_df['czas'] = pd.to_datetime(merged_df['czas'])\n",
    "    assert merged_df['czas'].is_monotonic_increasing\n",
    "\n",
    "    merged_df.to_csv(dir_path + 'merged.csv', index=False)\n",
    "    \n",
    "    return merged_df\n",
    "df_og = merge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15b2af29-c884-4205-9621-5c1c8169a510",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kacper/studia/cuvalley/data_processing.py:128: FutureWarning: The pandas.datetime class is deprecated and will be removed from pandas in a future version. Import from datetime module instead.\n",
      "  if not type(agg_df['czas']) is pd.datetime:\n"
     ]
    }
   ],
   "source": [
    "k = 15 # number of minutes in cluster\n",
    "df_og = aggregate(df_og, k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Proste featury wybieram albo tworze agregując"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(index=df_og.index)\n",
    "\n",
    "# srednia po 'WODY POWROTNE KOLEKTORÓW [°C]'\n",
    "TIR = df_og.columns[df_og.columns.str.contains('tir')].values\n",
    "df['TIR'] = df_og[TIR].mean(axis='columns')\n",
    "\n",
    "# srednia po 'TEMP POD 2 WARSTWĄ WYMURÓWKI [°C]'\n",
    "TIX1 = df_og.columns[df_og.columns.str.contains('001tix')].values\n",
    "df['TIX1'] = df_og[TIX1].mean(axis='columns')\n",
    "\n",
    "# prob_s i prob_corg\n",
    "PR = ['prob_s', 'prob_corg']\n",
    "df[PR] = df_og[PR]\n",
    "\n",
    "# reg nadawy koncentratu\n",
    "FCX = df_og.columns[df_og.columns.str.contains('fcx')].values\n",
    "df['FCX'] = df_og[FCX].mean(axis='columns')\n",
    "\n",
    "# sumaryczna moc cieplna\n",
    "NIR = df_og.columns[df_og.columns.str.contains('nir')].values\n",
    "df['NIR'] = df_og[NIR]\n",
    "\n",
    "# WENT ODCZ ZAD OBROTÓW\n",
    "UXM = df_og.columns[df_og.columns.str.contains('uxm')].values\n",
    "df['UXM'] = df_og[UXM].mean(axis='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading mean and scale from historical data to standarize features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = pickle.load(open('mean.sav', 'rb'))\n",
    "scl = pickle.load(open('scale.sav', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Standarizing data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = df.sub(mean).div(scl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'finalized_model.sav'\n",
    "model = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1302.0926024 , 1302.01186837, 1301.96772103, ..., 1300.6801952 ,\n",
       "       1300.53592092, 1300.43068693])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
